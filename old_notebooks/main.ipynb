{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8197517,"sourceType":"datasetVersion","datasetId":4855812},{"sourceId":8198775,"sourceType":"datasetVersion","datasetId":4856749}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\n\nThe goal of this project is to develop a model that classifies types of supernovae based on their light curves, specifically focusing on photometric data. The task at hand is to distinguish between two primary types of supernovae: Type I (SN I) and Type II (SN II) through binary classification.\n\nThis study draws inspiration from a research paper which explores advanced preprocessing methods for constructing light curves using Gaussian processes. The paper, which can be accessed [here](https://arxiv.org/abs/2105.06178), details the use of Gaussian processes to smooth and interpolate the raw photometric data, thereby facilitating better feature extraction for subsequent classification tasks.\n\nThe model we intend to build, referred to as \"T2\", is based on the transformer architecture.In this project, we leverage the transformer model to process the time-series data derived from the light curves of supernovae, aiming to efficiently classify these astronomical events into their respective types.","metadata":{}},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\n#import importlib\n#import src.preprocessing.tools as tools\n#import src.preprocessing.load_csv as load_csv\n#import src.preprocessing.plot_data as plot_data\n#import src.preprocessing.data_augmentation as data_augmentation\n#import src.evaluation.plot_evaluation as plot_evaluation\n\n#importlib.reload(plot_evaluation)\n#importlib.reload(data_augmentation)\n#importlib.reload(load_csv)\n#importlib.reload(plot_data)\n#importlib.reload(tools)\n\n#from src.preprocessing.load_csv import load_BTS_data, load_all_photometry\n#from src.preprocessing.plot_data import plot_types_distributions, plot_photometry, plot_gp\n#from src.preprocessing.tools import categorize_type, Mag2Flux, Normalize_mjd, count_obj_by_type, robust_scale\n#from src.preprocessing.data_augmentation import augment_data_with_noise, balanced_augmentation\n#from src.evaluation.plot_evaluation import plot_history, plot_multi_class_roc, plot_confusion_matrix, plot_class_accuracy, early_classification_tradeoff","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:48:30.320979Z","iopub.execute_input":"2024-04-23T00:48:30.321369Z","iopub.status.idle":"2024-04-23T00:48:30.327040Z","shell.execute_reply.started":"2024-04-23T00:48:30.321340Z","shell.execute_reply":"2024-04-23T00:48:30.326087Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Data Selection","metadata":{}},{"cell_type":"code","source":"df = load_BTS_data('data/BTS.csv')\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_types_distributions(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Project Overview\n\nThe main objective of this project is to explore and test various feature extraction methods for photometric data on supernovae.\n\n### Data Categorization\n\nFor the purpose of this analysis, I have chosen to categorize the supernovae into three distinct groups:\n- **Type I Supernovae (SN I)**: This category includes all Type I supernovae.\n- **Type II Supernovae (SN II)**: This group encompasses all Type II supernovae.\n- **Other**: Any supernovae that do not fit into the above two categories will be classified under 'Other'.","metadata":{}},{"cell_type":"code","source":"df['type'] = df['type'].apply(categorize_type)\nplot_types_distributions(df)\nplot_types_distributions(df, form='pie')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA_DIRECTORY = \"/media/theob/E/ML_project_data/data\"\n# photo_df = load_all_photometry(df, DATA_DIRECTORY, save=True)\n\nphoto_df = pd.read_csv('data/photometry_Other_SN_I_SN_II.csv')\nphoto_df = photo_df[photo_df['filter'].isin(['ztfg', 'ztfr', 'ztfi'])]\nphoto_df.dropna(inplace=True)\nphoto_df.reset_index(drop=True, inplace=True)\nphoto_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Augmentation Function Explanation\n\nThe function `augment_data_with_noise` is designed to enhance the robustness of our machine learning models by creating augmented versions of the original dataset. This data augmentation process involves manipulating the photometric data of each observed supernova object in the following manner:\n\n1. **Subset Creation**: For each unique object in the dataset, we create three subsets containing 80%, 50%, and 20% of the original data points, based on the measurement dates (`mjd`). This step simulates scenarios where only a portion of the data is available, mimicking real-world observational limitations.\n\n2. **Noise Addition**: To each of these subsets, we add Gaussian noise to the photometric measurements (`mag` for magnitude and `magerr` for magnitude error). The noise is scaled by a specified `noise_level` parameter and is calculated as a fraction of the standard deviation of the data in the flux columns. This step is intended to test the model's ability to handle observational noise and variability in data quality.\n\n3. **Data Integration**: The augmented data entries, which now represent the original object under different observational conditions and noise levels, are then labeled with a unique identifier and combined back into the main dataset.\n","metadata":{}},{"cell_type":"code","source":"# photo_df = augment_data_with_noise(photo_df, noise_level=0.05)\n# photo_df.to_csv('augmented_SNI_SNII_Other_photometry.csv', index=False)\n\nphoto_df = pd.read_csv('data/augmented_SNI_SNII_Other_photometry.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set a base ID for filtering\nid_base = 'ZTF20abzoeiw'  # Hard-coded example ID\n\n# Collect all IDs from the DataFrame that start with the base ID\nrelevant_ids = [obj_id for obj_id in photo_df['obj_id'].unique() if obj_id.startswith(id_base)]\n\n# Iterate through each relevant ID, retrieve the corresponding data, and plot the photometry\nfor i, obj_id in enumerate(relevant_ids):\n    one_df = photo_df[photo_df['obj_id'] == obj_id]  # Get the DataFrame for the current object ID\n    plot_photometry(one_df)  # Call a function to plot photometry data for this DataFrame\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conversion of Magnitude to Flux\n\nTo analyze the photometric data effectively using Gaussian processes, we first convert the observed magnitudes into flux measurements. The conversion from magnitude (`mag`) to flux (`flux`) is based on the following formula:\n\n$$\n\\text{flux} = 10^{-0.4 \\times (\\text{mag} - 23.9)}\n$$\n\nAdditionally, we calculate the flux error (`flux_error`) using the associated magnitude error (`magerr`), with the conversion given by:\n\n$$\n\\text{flux\\_error} = \\left( \\frac{\\text{magerr}}{2.5 / \\ln(10)} \\right) \\times \\text{flux}\n$$\n\nThis formula adjusts the magnitude error to be proportional to the flux based on the logarithmic relationship between flux and magnitude.\n\n### Normalization of Modified Julian Date (MJD)\n\nThe temporal information for each object, given by the Modified Julian Date (MJD), is normalized so that each object's observational timeline starts at zero.","metadata":{}},{"cell_type":"code","source":"photo_df = Mag2Flux(photo_df)\nphoto_df = Normalize_mjd(photo_df)\nphoto_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_obj_by_type(photo_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Filtering Criteria\n\nWe only retain objects in our dataset that meet the following conditions for reliable analysis:\n- Each object must have **at least three observations**.\n- These observations must be across **at least two different filters**.\n\nThis filtering ensures the dataset includes only those objects with sufficient data spread across multiple spectral bands, essential for robust analysis.","metadata":{}},{"cell_type":"code","source":"filtered_df = photo_df.groupby('obj_id').filter(lambda x: x.groupby('filter')['mjd'].count().ge(3).sum() >= 2)\nfiltered_df.reset_index(drop=True, inplace=True)\ncount_obj_by_type(filtered_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_df = pd.read_csv('data/filtered_SNI_SNII_Other_photometry.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Interpolation with Gaussian Processes\n\nWe employ Gaussian Process (GP) regression to preprocess our photometric data, leveraging the method's capacity to handle irregular sampling and heteroskedastic errors. This approach, inspired by *Paying Attention to Astronomical Transients*, is especially useful for modeling supernova light curves which often have sparse and irregular observations.\n\n#### Key Implementation:\n- **Kernel Choice**: We use a 2-dimensional Matern kernel, adapted from Boone (2019), to account for both time and wavelength, enhancing predictions across different passbands.\n- **Application**: The GP is trained on subsets of original data and then used to predict light curves at regular intervals, thus standardizing the time-series data for further analysis.\n","metadata":{}},{"cell_type":"markdown","source":"![](assets/gp_explain.png)","metadata":{}},{"cell_type":"code","source":"# Create a DataFrame 'mini_data' that excludes any objects with IDs containing '_xx' where 'xx' are numbers. This helps isolate original objects without derived versions.\nmini_data = filtered_df[~filtered_df['obj_id'].str.contains('_')]\ncount_obj_by_type(mini_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Uncomment the below lines to fit a 2D Gaussian Process on 'mini_data' and use the resulting kernel for processing the 'filtered_df'.\n# kernel, _ = fit_2d_gp(mini_data, kernel=None, return_kernel=True)\n# all_gp = process_gaussian(filtered_df, kernel=kernel, name='all', save=True)\n\n# Load the preprocessed Gaussian Process results from a CSV file into the DataFrame 'all_gp'.\nall_gp = pd.read_csv('/kaggle/input/all-gp-othersnisnii/all_gp_Other_SN_I_SN_II.csv')\n\n# Display the first few rows of the DataFrame 'all_gp' to show the results of the Gaussian Process.\nall_gp[all_gp['obj_id'] == 'ZTF23abieafn'].head()\nall_gp","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:48:56.435489Z","iopub.execute_input":"2024-04-23T00:48:56.436201Z","iopub.status.idle":"2024-04-23T00:49:07.637087Z","shell.execute_reply.started":"2024-04-23T00:48:56.436172Z","shell.execute_reply":"2024-04-23T00:49:07.636078Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"               mjd   flux_ztfg   flux_ztfr  flux_error_ztfg  flux_error_ztfr  \\\n0         0.000000   80.564993   75.533946        28.944867        11.766348   \n1         0.302880   81.341945   76.189773        28.734096        11.600245   \n2         0.605760   82.119929   76.842398        28.536516        11.528653   \n3         0.908640   82.898872   77.492132        28.350732        11.539058   \n4         1.211520   83.678702   78.139275        28.175217        11.617625   \n...            ...         ...         ...              ...              ...   \n4143095  19.892972  104.480231  110.818564        15.981438         8.654353   \n4143096  20.102372  104.307420  110.616096        16.341666         8.768329   \n4143097  20.311772  104.111913  110.387063        16.700319         8.910966   \n4143098  20.521171  103.894191  110.131634        17.058280         9.088578   \n4143099  20.730571  103.654746  109.849948        17.416381         9.307106   \n\n          type           obj_id  flux_ztfi  flux_error_ztfi  \n0        Other     ZTF17aaajowi        NaN              NaN  \n1        Other     ZTF17aaajowi        NaN              NaN  \n2        Other     ZTF17aaajowi        NaN              NaN  \n3        Other     ZTF17aaajowi        NaN              NaN  \n4        Other     ZTF17aaajowi        NaN              NaN  \n...        ...              ...        ...              ...  \n4143095  Other  ZTF24aahdisu_80        NaN              NaN  \n4143096  Other  ZTF24aahdisu_80        NaN              NaN  \n4143097  Other  ZTF24aahdisu_80        NaN              NaN  \n4143098  Other  ZTF24aahdisu_80        NaN              NaN  \n4143099  Other  ZTF24aahdisu_80        NaN              NaN  \n\n[4143100 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mjd</th>\n      <th>flux_ztfg</th>\n      <th>flux_ztfr</th>\n      <th>flux_error_ztfg</th>\n      <th>flux_error_ztfr</th>\n      <th>type</th>\n      <th>obj_id</th>\n      <th>flux_ztfi</th>\n      <th>flux_error_ztfi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>80.564993</td>\n      <td>75.533946</td>\n      <td>28.944867</td>\n      <td>11.766348</td>\n      <td>Other</td>\n      <td>ZTF17aaajowi</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.302880</td>\n      <td>81.341945</td>\n      <td>76.189773</td>\n      <td>28.734096</td>\n      <td>11.600245</td>\n      <td>Other</td>\n      <td>ZTF17aaajowi</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.605760</td>\n      <td>82.119929</td>\n      <td>76.842398</td>\n      <td>28.536516</td>\n      <td>11.528653</td>\n      <td>Other</td>\n      <td>ZTF17aaajowi</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.908640</td>\n      <td>82.898872</td>\n      <td>77.492132</td>\n      <td>28.350732</td>\n      <td>11.539058</td>\n      <td>Other</td>\n      <td>ZTF17aaajowi</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.211520</td>\n      <td>83.678702</td>\n      <td>78.139275</td>\n      <td>28.175217</td>\n      <td>11.617625</td>\n      <td>Other</td>\n      <td>ZTF17aaajowi</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4143095</th>\n      <td>19.892972</td>\n      <td>104.480231</td>\n      <td>110.818564</td>\n      <td>15.981438</td>\n      <td>8.654353</td>\n      <td>Other</td>\n      <td>ZTF24aahdisu_80</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4143096</th>\n      <td>20.102372</td>\n      <td>104.307420</td>\n      <td>110.616096</td>\n      <td>16.341666</td>\n      <td>8.768329</td>\n      <td>Other</td>\n      <td>ZTF24aahdisu_80</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4143097</th>\n      <td>20.311772</td>\n      <td>104.111913</td>\n      <td>110.387063</td>\n      <td>16.700319</td>\n      <td>8.910966</td>\n      <td>Other</td>\n      <td>ZTF24aahdisu_80</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4143098</th>\n      <td>20.521171</td>\n      <td>103.894191</td>\n      <td>110.131634</td>\n      <td>17.058280</td>\n      <td>9.088578</td>\n      <td>Other</td>\n      <td>ZTF24aahdisu_80</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4143099</th>\n      <td>20.730571</td>\n      <td>103.654746</td>\n      <td>109.849948</td>\n      <td>17.416381</td>\n      <td>9.307106</td>\n      <td>Other</td>\n      <td>ZTF24aahdisu_80</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4143100 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Data Scaling with RobustScaler\n\nWe apply `RobustScaler` from scikit-learn to columns specified in the `robust_scale` function. This scaler removes the median and scales the data according to the quantile range, making it robust against outliers.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\n\ndef robust_scale(dataframe, scale_columns):\n    scaler = RobustScaler()\n    scaler = scaler.fit(dataframe[scale_columns])\n    dataframe.loc[:, scale_columns] = scaler.transform(\n        dataframe[scale_columns].to_numpy()\n    )\n    return dataframe","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:49:25.309095Z","iopub.execute_input":"2024-04-23T00:49:25.309466Z","iopub.status.idle":"2024-04-23T00:49:26.303203Z","shell.execute_reply.started":"2024-04-23T00:49:25.309438Z","shell.execute_reply":"2024-04-23T00:49:26.302201Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"scale_columns = ['flux_ztfg', 'flux_ztfr', 'flux_ztfi', 'flux_error_ztfg', 'flux_error_ztfr', 'flux_error_ztfi']\nall_gp = robust_scale(all_gp, scale_columns)\nall_gp[all_gp['obj_id'] == 'ZTF23abieafn'].head()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:49:27.231089Z","iopub.execute_input":"2024-04-23T00:49:27.231825Z","iopub.status.idle":"2024-04-23T00:49:28.781355Z","shell.execute_reply.started":"2024-04-23T00:49:27.231795Z","shell.execute_reply":"2024-04-23T00:49:28.780336Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RobustScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"              mjd  flux_ztfg  flux_ztfr  flux_error_ztfg  flux_error_ztfr  \\\n1159000  0.000000  -0.258734  -0.495969         1.198247         0.454021   \n1159001  0.756231  -0.170560  -0.396979         0.962248         0.309503   \n1159002  1.512462  -0.080327  -0.294698         0.727151         0.191094   \n1159003  2.268693   0.011719  -0.190446         0.493854         0.081854   \n1159004  3.024924   0.105321  -0.085568         0.264012        -0.031899   \n\n         type        obj_id  flux_ztfi  flux_error_ztfi  \n1159000  SN I  ZTF23abieafn  -0.626088         1.563590  \n1159001  SN I  ZTF23abieafn  -0.559298         1.510487  \n1159002  SN I  ZTF23abieafn  -0.492304         1.460251  \n1159003  SN I  ZTF23abieafn  -0.425519         1.412428  \n1159004  SN I  ZTF23abieafn  -0.359376         1.366536  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mjd</th>\n      <th>flux_ztfg</th>\n      <th>flux_ztfr</th>\n      <th>flux_error_ztfg</th>\n      <th>flux_error_ztfr</th>\n      <th>type</th>\n      <th>obj_id</th>\n      <th>flux_ztfi</th>\n      <th>flux_error_ztfi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1159000</th>\n      <td>0.000000</td>\n      <td>-0.258734</td>\n      <td>-0.495969</td>\n      <td>1.198247</td>\n      <td>0.454021</td>\n      <td>SN I</td>\n      <td>ZTF23abieafn</td>\n      <td>-0.626088</td>\n      <td>1.563590</td>\n    </tr>\n    <tr>\n      <th>1159001</th>\n      <td>0.756231</td>\n      <td>-0.170560</td>\n      <td>-0.396979</td>\n      <td>0.962248</td>\n      <td>0.309503</td>\n      <td>SN I</td>\n      <td>ZTF23abieafn</td>\n      <td>-0.559298</td>\n      <td>1.510487</td>\n    </tr>\n    <tr>\n      <th>1159002</th>\n      <td>1.512462</td>\n      <td>-0.080327</td>\n      <td>-0.294698</td>\n      <td>0.727151</td>\n      <td>0.191094</td>\n      <td>SN I</td>\n      <td>ZTF23abieafn</td>\n      <td>-0.492304</td>\n      <td>1.460251</td>\n    </tr>\n    <tr>\n      <th>1159003</th>\n      <td>2.268693</td>\n      <td>0.011719</td>\n      <td>-0.190446</td>\n      <td>0.493854</td>\n      <td>0.081854</td>\n      <td>SN I</td>\n      <td>ZTF23abieafn</td>\n      <td>-0.425519</td>\n      <td>1.412428</td>\n    </tr>\n    <tr>\n      <th>1159004</th>\n      <td>3.024924</td>\n      <td>0.105321</td>\n      <td>-0.085568</td>\n      <td>0.264012</td>\n      <td>-0.031899</td>\n      <td>SN I</td>\n      <td>ZTF23abieafn</td>\n      <td>-0.359376</td>\n      <td>1.366536</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"obj_ids = all_gp['obj_id'].unique()\nfor i in range(5):\n    id_1 = random.choice(obj_ids)\n    one_df = all_gp[all_gp['obj_id'] == id_1]\n    plot_gp(one_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:03:39.238523Z","iopub.execute_input":"2024-04-22T22:03:39.238878Z","iopub.status.idle":"2024-04-22T22:03:40.338606Z","shell.execute_reply.started":"2024-04-22T22:03:39.238850Z","shell.execute_reply":"2024-04-22T22:03:40.337182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling Missing Data in Filters\n\nMany objects in our dataset exhibit zero recorded observations for one or more filters, resulting in numerous NaN (Not a Number) values. This absence of data can distort the analysis and model training process.\n\nTo ensure the integrity and effectiveness of our models, we preemptively remove any instances with NaN values from our dataset before proceeding with data preparation for modeling.","metadata":{}},{"cell_type":"code","source":"all_gp.dropna(inplace=True)\nall_gp.reset_index(inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Augmentation Techniques\n\nTo enhance the robustness and generalization ability of our models, we employ several data augmentation techniques. Each method manipulates the data slightly differently to simulate various scenarios or introduce subtle variations that help the model learn more general features.","metadata":{}},{"cell_type":"code","source":"augmented_df = balanced_augmentation(all_gp)\naugmented_df.to_csv('data/augmented_gp_Other_SN_I_SN_II.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmented_df = pd.read_csv('data/augmented_gp_Other_SN_I_SN_II.csv')\ncount_obj_by_type(all_gp)\ncount_obj_by_type(augmented_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Techniques Overview:","metadata":{}},{"cell_type":"code","source":"sn_ii_ids = augmented_df[augmented_df['type'] == 'SN II']['obj_id'].unique()\nsn_ii_id = random.choice(sn_ii_ids)\nsn_ii_id = 'ZTF23aaohqcn'\nplot_gp(augmented_df[augmented_df['obj_id'] == sn_ii_id])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. **Magnitude Warp**:\n   - **Purpose**: Alters the magnitude of the data series to simulate changes in intensity.\n   - **Implementation**: Uses cubic spline interpolation to smoothly vary the series magnitudes based on randomly generated control points.","metadata":{}},{"cell_type":"code","source":"plot_gp(augmented_df[augmented_df['obj_id'] == sn_ii_id + '_magnitude_warp'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. **Shuffle Features**:\n   - **Purpose**: Shuffles the order of features to test the model's dependency on the sequence of input features.\n   - **Implementation**: Randomly shuffles the series along the feature dimension, preserving the temporal sequence.","metadata":{}},{"cell_type":"code","source":"plot_gp(augmented_df[augmented_df['obj_id'] == sn_ii_id + '_shuffle_features'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. **Add Gaussian Noise**:\n   - **Purpose**: Introduces random noise to the data series to mimic observational noise.\n   - **Implementation**: Adds Gaussian noise to each point in the series, simulating real-world data collection imperfections.","metadata":{}},{"cell_type":"code","source":"plot_gp(augmented_df[augmented_df['obj_id'] == sn_ii_id + '_gaussian_noise'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_obj_by_type(df):\n    obj_id_count_per_type = df.groupby('type')['obj_id'].nunique()\n    print(obj_id_count_per_type)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:49:52.266448Z","iopub.execute_input":"2024-04-23T00:49:52.266806Z","iopub.status.idle":"2024-04-23T00:49:52.271823Z","shell.execute_reply.started":"2024-04-23T00:49:52.266780Z","shell.execute_reply":"2024-04-23T00:49:52.270935Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"count_obj_by_type(all_gp)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:49:52.767408Z","iopub.execute_input":"2024-04-23T00:49:52.767780Z","iopub.status.idle":"2024-04-23T00:49:53.608286Z","shell.execute_reply.started":"2024-04-23T00:49:52.767751Z","shell.execute_reply":"2024-04-23T00:49:53.607370Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"type\nOther    13453\nSN I     21960\nSN II     6018\nName: obj_id, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ndef augment_light_curves(df, target_type, shift_value=5):\n    # Sélectionner uniquement les objets du type spécifié\n    target_df = df[df['type'] == target_type].copy()\n    \n    # Ajouter un suffixe '_aug' à 'obj_id' pour les entrées sélectionnées\n    target_df['obj_id'] = target_df['obj_id'] + '_aug'\n    \n    # Identifier les colonnes de flux et d'erreur de flux\n    flux_cols = [col for col in df.columns if 'flux' in col and 'error' not in col]\n    error_cols = [col for col in df.columns if 'flux_error' in col]\n\n    # Appliquer le décalage et l'interpolation\n    tqdm.pandas(desc=\"Augmenting data\")  # Initialiser tqdm pour le traitement avec progress_apply\n    target_df = target_df.groupby('obj_id').progress_apply(lambda group: shift_and_interpolate(group, flux_cols, error_cols, shift_value))\n    \n    # Combiner le DataFrame original avec les données augmentées\n    final_df = pd.concat([df, target_df], ignore_index=True)\n    \n    return final_df\n\ndef shift_and_interpolate(group, flux_cols, error_cols, shift_value):\n    # Décaler les données de flux et d'erreur\n    for col in flux_cols + error_cols:\n        group[col] = group[col].shift(-shift_value)\n    \n    # Interpoler les valeurs NaN générées par le décalage\n    group[flux_cols + error_cols].interpolate(method='linear', inplace=True, limit_direction='forward')\n    \n    return group","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:16:25.666142Z","iopub.execute_input":"2024-04-23T01:16:25.666505Z","iopub.status.idle":"2024-04-23T01:16:25.675249Z","shell.execute_reply.started":"2024-04-23T01:16:25.666478Z","shell.execute_reply":"2024-04-23T01:16:25.674272Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Exemple d'utilisation\n# df est votre DataFrame initial\n# 'SN I' est le type que vous souhaitez augmenter\naugmented_df = augment_light_curves(all_gp, 'Other')","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:53:26.062505Z","iopub.execute_input":"2024-04-23T00:53:26.063249Z","iopub.status.idle":"2024-04-23T00:54:55.227924Z","shell.execute_reply.started":"2024-04-23T00:53:26.063205Z","shell.execute_reply":"2024-04-23T00:54:55.227093Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Augmenting data:   0%|          | 0/13453 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55e7514063d9418598fe0b99222a3874"}},"metadata":{}}]},{"cell_type":"code","source":"count_obj_by_type(augmented_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T00:54:55.229666Z","iopub.execute_input":"2024-04-23T00:54:55.229951Z","iopub.status.idle":"2024-04-23T00:54:56.253555Z","shell.execute_reply.started":"2024-04-23T00:54:55.229928Z","shell.execute_reply":"2024-04-23T00:54:56.252543Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"type\nOther    26906\nSN I     21960\nSN II     6018\nName: obj_id, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"augmented_df = augment_light_curves(augmented_df, 'SN II')","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:16:30.562385Z","iopub.execute_input":"2024-04-23T01:16:30.563192Z","iopub.status.idle":"2024-04-23T01:21:37.573101Z","shell.execute_reply.started":"2024-04-23T01:16:30.563160Z","shell.execute_reply":"2024-04-23T01:21:37.572314Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"Augmenting data:   0%|          | 0/30090 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6c153b1f1734ef8b75e398421cc4b09"}},"metadata":{}}]},{"cell_type":"code","source":"count_obj_by_type(all_gp)\ncount_obj_by_type(augmented_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:21:37.574605Z","iopub.execute_input":"2024-04-23T01:21:37.574891Z","iopub.status.idle":"2024-04-23T01:21:44.519217Z","shell.execute_reply.started":"2024-04-23T01:21:37.574868Z","shell.execute_reply":"2024-04-23T01:21:44.518336Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"type\nOther    13453\nSN I     21960\nSN II     6018\nName: obj_id, dtype: int64\ntype\nOther    40359\nSN I     43920\nSN II    36108\nName: obj_id, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"augmented_df.fillna(-999.0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:21:48.117349Z","iopub.execute_input":"2024-04-23T01:21:48.117707Z","iopub.status.idle":"2024-04-23T01:21:53.708651Z","shell.execute_reply.started":"2024-04-23T01:21:48.117680Z","shell.execute_reply":"2024-04-23T01:21:53.707815Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"augmented_df.to_csv('aug_shift_df.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:23:40.139133Z","iopub.execute_input":"2024-04-23T01:23:40.139513Z","iopub.status.idle":"2024-04-23T01:26:08.705944Z","shell.execute_reply.started":"2024-04-23T01:23:40.139484Z","shell.execute_reply":"2024-04-23T01:26:08.704687Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\noriginal_ids = augmented_df['obj_id'].apply(lambda x: x.split('_')[0]).unique()\n\n# Split des ID originaux en train et test sets\ntrain_orig_ids, test_orig_ids = train_test_split(original_ids, test_size=0.2, random_state=42)\n\n# Fonction pour vérifier si un obj_id augmenté appartient à l'ensemble des ID originaux de train ou de test\ndef is_in_set(x, id_set):\n    base_id = x.split('_')[0]\n    return base_id in id_set\n\n# Créez les DataFrames de train et de test basés sur les IDs splités\ntrain_data = augmented_df[augmented_df['obj_id'].apply(is_in_set, id_set=set(train_orig_ids))]\ntest_data = augmented_df[augmented_df['obj_id'].apply(is_in_set, id_set=set(test_orig_ids))]\n\n# Affichez les informations pour vérifier\nprint(f\"Training data size: {train_data.shape}\")\nprint(f\"Test data size: {test_data.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:21:56.098179Z","iopub.execute_input":"2024-04-23T01:21:56.098555Z","iopub.status.idle":"2024-04-23T01:23:27.219575Z","shell.execute_reply.started":"2024-04-23T01:21:56.098524Z","shell.execute_reply":"2024-04-23T01:23:27.218491Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Training data size: (23261400, 9)\nTest data size: (5769400, 9)\n","output_type":"stream"}]},{"cell_type":"code","source":"count_obj_by_type(train_data)\ncount_obj_by_type(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:23:27.221685Z","iopub.execute_input":"2024-04-23T01:23:27.222394Z","iopub.status.idle":"2024-04-23T01:23:33.358538Z","shell.execute_reply.started":"2024-04-23T01:23:27.222356Z","shell.execute_reply":"2024-04-23T01:23:33.357480Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"type\nOther    31851\nSN I     35266\nSN II    29040\nName: obj_id, dtype: int64\ntype\nOther    8508\nSN I     8654\nSN II    7068\nName: obj_id, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Preparation for Modeling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom keras.preprocessing.sequence import pad_sequences\n\ndef prepare_data(df):\n    grouped = df.groupby('obj_id')\n    sequences = [group[['mjd', 'flux_ztfg', 'flux_ztfi', 'flux_ztfr']].values for _, group in grouped]\n    \n    types = df[['obj_id', 'type']].drop_duplicates().sort_values('obj_id')['type']\n    encoder = OneHotEncoder(sparse_output=False)\n    encoded_labels = encoder.fit_transform(types.values.reshape(-1, 1))\n    label_names = encoder.categories_[0]\n    \n    padded_sequences = pad_sequences(sequences, padding='post', dtype='float32')\n    \n    return padded_sequences, encoded_labels, label_names\n\nX_train, y_train, label_names = prepare_data(train_data)\nX_test, y_test, label_names_test = prepare_data(test_data)\n\nprint(\"X_train shape:\", X_train.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"y_test shape:\", y_test.shape)\nprint(\"Label names:\", label_names)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:46:52.035958Z","iopub.execute_input":"2024-04-22T23:46:52.036896Z","iopub.status.idle":"2024-04-22T23:47:06.603780Z","shell.execute_reply.started":"2024-04-22T23:46:52.036861Z","shell.execute_reply":"2024-04-22T23:47:06.602198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom keras.preprocessing.sequence import pad_sequences\n\ndef prepare_data(df):\n    grouped = df.groupby('obj_id')\n    sequences = [group[['mjd', 'flux_ztfg', 'flux_ztfi', 'flux_ztfr']].values for _, group in grouped]\n    \n    # Extraction de 'obj_id' et 'type' pour chaque groupe\n    types_df = df[['obj_id', 'type']].drop_duplicates().sort_values('obj_id')\n    encoder = OneHotEncoder(sparse_output=False)\n    encoded_labels = encoder.fit_transform(types_df['type'].values.reshape(-1, 1))\n    label_names = encoder.categories_[0]\n    \n    padded_sequences = pad_sequences(sequences, padding='post', dtype='float32')\n    \n    return padded_sequences, encoded_labels, label_names, types_df  # Include obj_id in the output\n\n# Utilisation adaptée de la fonction prepare_data\nX_train, y_train, label_names, y_train_df = prepare_data(train_data)\nX_test, y_test, label_names_test, y_test_df = prepare_data(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:27:38.529380Z","iopub.execute_input":"2024-04-23T01:27:38.530075Z","iopub.status.idle":"2024-04-23T01:29:14.017631Z","shell.execute_reply.started":"2024-04-23T01:27:38.530045Z","shell.execute_reply":"2024-04-23T01:29:14.016646Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"2024-04-23 01:27:40.252197: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-23 01:27:40.252326: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-23 01:27:40.374822: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\n\ndef save_data(X_train, y_train, X_test, y_test, label_names, data_path='data/'):\n    # Save X_train data\n    np.save(data_path + 'X_train.npy', X_train)\n    print(\"Training data saved successfully to:\", data_path + 'X_train.npy')\n    \n    # Save X_test data\n    np.save(data_path + 'X_test.npy', X_test)\n    print(\"Test data saved successfully to:\", data_path + 'X_test.npy')\n    \n    # Save y_train data\n    np.save(data_path + 'y_train.npy', y_train)\n    print(\"Training labels saved successfully to:\", data_path + 'y_train.npy')\n    \n    # Save y_test data\n    np.save(data_path + 'y_test.npy', y_test)\n    print(\"Test labels saved successfully to:\", data_path + 'y_test.npy')\n    \n    # Save label names to JSON\n    label_names_list = label_names.tolist()\n    with open(data_path + 'label_names.json', 'w') as f:\n        json.dump(label_names_list, f)\n    print(\"Label names saved successfully to:\", data_path + 'label_names.json')\n\ndef load_data(data_path='/kaggle/input/train-test-phot/'):\n    X_train = np.load(data_path + 'X_train.npy')\n    X_test = np.load(data_path + 'X_test.npy')\n    y_train = np.load(data_path + 'y_train.npy')\n    y_test = np.load(data_path + 'y_test.npy')\n\n    with open(data_path + 'label_names.json', 'r') as f:\n        label_names = json.load(f)\n\n    return X_train, y_train, X_test, y_test, label_names","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:19:29.148202Z","iopub.execute_input":"2024-04-22T22:19:29.148868Z","iopub.status.idle":"2024-04-22T22:19:29.158296Z","shell.execute_reply.started":"2024-04-22T22:19:29.148840Z","shell.execute_reply":"2024-04-22T22:19:29.157208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_data(X_train, y_train, X_test, y_test, label_names)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:19:30.075687Z","iopub.execute_input":"2024-04-22T22:19:30.076060Z","iopub.status.idle":"2024-04-22T22:19:30.570715Z","shell.execute_reply.started":"2024-04-22T22:19:30.076032Z","shell.execute_reply":"2024-04-22T22:19:30.569423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train, X_test, y_test, label_names = load_data()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T18:18:39.947154Z","iopub.execute_input":"2024-04-22T18:18:39.947840Z","iopub.status.idle":"2024-04-22T18:18:41.002103Z","shell.execute_reply.started":"2024-04-22T18:18:39.947809Z","shell.execute_reply":"2024-04-22T18:18:41.001133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplt.bar(label_names, y_train.sum(axis=0))\nplt.title('Distribution of labels in the training set')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:29:14.019327Z","iopub.execute_input":"2024-04-23T01:29:14.019903Z","iopub.status.idle":"2024-04-23T01:29:14.224251Z","shell.execute_reply.started":"2024-04-23T01:29:14.019877Z","shell.execute_reply":"2024-04-23T01:29:14.223326Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"print(\"NaN in X_train:\", np.isnan(X_train).any())\nprint(\"Inf in X_train:\", np.isinf(X_train).any())","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:29:19.103505Z","iopub.execute_input":"2024-04-23T01:29:19.103886Z","iopub.status.idle":"2024-04-23T01:29:19.605921Z","shell.execute_reply.started":"2024-04-23T01:29:19.103856Z","shell.execute_reply":"2024-04-23T01:29:19.604942Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"NaN in X_train: False\nInf in X_train: False\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Class weight","metadata":{}},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n\ny_train_integers = np.argmax(y_train, axis=1)\nclass_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_integers), y=y_train_integers)\nclass_weight_dict = {i : class_weights[i] for i in range(len(class_weights))}\n\nclass_weight_dict","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:29:20.019364Z","iopub.execute_input":"2024-04-23T01:29:20.020180Z","iopub.status.idle":"2024-04-23T01:29:20.051245Z","shell.execute_reply.started":"2024-04-23T01:29:20.020149Z","shell.execute_reply":"2024-04-23T01:29:20.050357Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"{0: 1.0063210992852134, 1: 0.9088735136770071, 2: 1.1037304866850322}"},"metadata":{}}]},{"cell_type":"markdown","source":"## T2 Model","metadata":{}},{"cell_type":"markdown","source":"![](assets/t2_model.png)","metadata":{}},{"cell_type":"code","source":"sequence_length = X_train.shape[1]\nfeature_dim = X_train.shape[2]\nnum_classes = y_train.shape[1]\n\nprint(\"Sequence length:\", sequence_length)\nprint(\"Feature dimension:\", feature_dim)\nprint(\"Number of classes:\", num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:29:23.228767Z","iopub.execute_input":"2024-04-23T01:29:23.229162Z","iopub.status.idle":"2024-04-23T01:29:23.235212Z","shell.execute_reply.started":"2024-04-23T01:29:23.229130Z","shell.execute_reply":"2024-04-23T01:29:23.234225Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Sequence length: 1000\nFeature dimension: 4\nNumber of classes: 3\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tensorflow_model_optimization","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:29:23.812423Z","iopub.execute_input":"2024-04-23T01:29:23.812783Z","iopub.status.idle":"2024-04-23T01:29:37.684814Z","shell.execute_reply.started":"2024-04-23T01:29:23.812756Z","shell.execute_reply":"2024-04-23T01:29:37.683567Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Collecting tensorflow_model_optimization\n  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\nRequirement already satisfied: absl-py~=1.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow_model_optimization) (1.4.0)\nRequirement already satisfied: dm-tree~=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow_model_optimization) (0.1.8)\nRequirement already satisfied: numpy~=1.23 in /opt/conda/lib/python3.10/site-packages (from tensorflow_model_optimization) (1.26.4)\nRequirement already satisfied: six~=1.14 in /opt/conda/lib/python3.10/site-packages (from tensorflow_model_optimization) (1.16.0)\nDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tensorflow_model_optimization\nSuccessfully installed tensorflow_model_optimization-0.8.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nimport tensorflow_model_optimization as tfmot\nimport numpy as np\nfrom tensorflow.keras.utils import register_keras_serializable\n\nclass PrunableClusterableLayer(\n    tf.keras.layers.Layer,\n    tfmot.sparsity.keras.PrunableLayer,\n    tfmot.clustering.keras.ClusterableLayer,\n):\n    def get_prunable_weights(self):\n        # Prune kernel only, as pruning bias can harm model accuracy.\n        return [self.conv1d.kernel]\n\n    def get_clusterable_weights(self):\n        # Cluster only the kernel as clustering bias usually harms model accuracy.\n        return [(\"kernel\", self.conv1d.kernel)]\n\n    def get_clusterable_algorithm(self, weight_name):\n        # Example algorithm, customize as necessary\n        if weight_name == \"kernel\":\n            return tfmot.clustering.keras.cluster_config.CentroidInitialization.LINEAR\n        else:\n            return None\n        \nclass ConvEmbedding(PrunableClusterableLayer):\n    def __init__(self, num_filters, kernel_size=1, activation='relu', **kwargs):\n        super(ConvEmbedding, self).__init__(**kwargs)\n        self.num_filters = num_filters\n        self.kernel_size = kernel_size\n        self.activation = activation\n        self.conv1d = layers.Conv1D(\n            filters=self.num_filters, kernel_size=self.kernel_size, activation=self.activation\n        )\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"num_filters\": self.num_filters,\n            \"kernel_size\": self.kernel_size,\n            \"activation\": self.activation,\n        })\n        return config\n\n    def call(self, inputs):\n        return self.conv1d(inputs)\n    \nclass PositionalEncoding(PrunableClusterableLayer):\n    def __init__(self, max_steps, max_dims, dtype=tf.float32, **kwargs):\n        super(PositionalEncoding, self).__init__(dtype=dtype, **kwargs)\n        self.max_steps = max_steps\n        self.max_dims = max_dims\n\n        if max_dims % 2 == 1:\n            max_dims += 1\n        p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n        pos_emb = np.empty((1, max_steps, max_dims))\n        pos_emb[0, :, ::2] = np.sin(p / 10000 ** (2 * i / max_dims)).T\n        pos_emb[0, :, 1::2] = np.cos(p / 10000 ** (2 * i / max_dims)).T\n        self.positional_embedding = tf.constant(pos_emb.astype(np.float32))\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"max_steps\": self.max_steps,\n            \"max_dims\": self.max_dims,\n        })\n        return config\n\n    def call(self, inputs):\n        shape = tf.shape(inputs)\n        return inputs + self.positional_embedding[:, :shape[1], :shape[2]]\n    \nclass MultiHeadSelfAttention(layers.Layer):\n    def __init__(self, embed_dim, num_heads):\n        super(MultiHeadSelfAttention, self).__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        if embed_dim % num_heads != 0:\n            raise ValueError(f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\")\n        self.projection_dim = embed_dim // num_heads\n        self.query_dense = layers.Dense(embed_dim)\n        self.key_dense = layers.Dense(embed_dim)\n        self.value_dense = layers.Dense(embed_dim)\n        self.combine_heads = layers.Dense(embed_dim)\n\n    def attention(self, query, key, value, mask):\n        score = tf.matmul(query, key, transpose_b=True)\n        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n        scaled_score = score / tf.math.sqrt(dim_key)\n        if mask is not None:\n            mask = tf.cast(mask, dtype=scaled_score.dtype)\n            scaled_score += (mask * -1e9)\n        weights = tf.nn.softmax(scaled_score, axis=-1)\n        output = tf.matmul(weights, value)\n        return output, weights\n\n    def separate_heads(self, x, batch_size):\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n        return tf.transpose(x, perm=[0, 2, 1, 3])\n\n    def call(self, inputs, mask):\n        batch_size = tf.shape(inputs)[0]\n        query = self.query_dense(inputs)\n        key = self.key_dense(inputs)\n        value = self.value_dense(inputs)\n        query = self.separate_heads(query, batch_size)\n        key = self.separate_heads(key, batch_size)\n        value = self.separate_heads(value, batch_size)\n\n        attention, weights = self.attention(query, key, value, mask)\n        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n        output = self.combine_heads(concat_attention)\n        return output\n    \nclass TransformerBlock(PrunableClusterableLayer):\n    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n        super(TransformerBlock, self).__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.ff_dim = ff_dim\n\n        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n        self.ffn = tf.keras.Sequential([\n            layers.Dense(ff_dim, activation=\"relu\"), \n            layers.Dense(embed_dim),\n        ])\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"embed_dim\": self.embed_dim,\n            \"num_heads\": self.num_heads,\n            \"ff_dim\": self.ff_dim,\n        })\n        return config\n\n    def call(self, inputs, training=False, mask=None):\n        attn_output = self.att(inputs, mask)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)\n    \nclass MaskingLayer(layers.Layer):\n    def __init__(self, mask_value=-999.0):\n        super(MaskingLayer, self).__init__()\n        self.mask_value = mask_value\n\n    def call(self, inputs):\n        mask = tf.math.not_equal(inputs, self.mask_value)\n        mask = tf.reduce_any(mask, axis=-1)\n        mask = mask[:, tf.newaxis, tf.newaxis, :]\n        return inputs, mask\n    \n@register_keras_serializable()\nclass T2Model(tf.keras.Model):\n    def __init__(self, num_filters, num_classes, num_layers, d_model, num_heads, dff, input_shape, rate=0.1):\n        super(T2Model, self).__init__()\n        self.num_filters = num_filters\n        self.num_classes = num_classes\n        self.num_layers = num_layers\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.dff = dff\n        self.rate = rate\n\n        self.masking_layer = MaskingLayer(mask_value=-999.0)\n        self.embedding = ConvEmbedding(num_filters=self.num_filters)\n        self.pos_encoding = PositionalEncoding(max_steps=input_shape[0], max_dims=d_model)\n        self.encoder_layers = [TransformerBlock(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n        self.dropout = layers.Dropout(rate)\n        self.final_layer = layers.Dense(num_classes, activation='softmax')\n\n    def call(self, inputs, training=False):\n        x, mask = self.masking_layer(inputs)\n        x = self.embedding(x)\n        x = self.pos_encoding(x)\n        \n        for layer in self.encoder_layers:\n            x = layer(x, training=training, mask=mask)\n\n        x = layers.GlobalAveragePooling1D()(x)\n        x = self.dropout(x, training=training)\n        return self.final_layer(x)\n\n    def build(self, input_shape):\n        inputs = tf.keras.Input(shape=input_shape)\n        _ = self.call(inputs)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:29:37.687175Z","iopub.execute_input":"2024-04-23T01:29:37.687635Z","iopub.status.idle":"2024-04-23T01:29:38.408981Z","shell.execute_reply.started":"2024-04-23T01:29:37.687606Z","shell.execute_reply":"2024-04-23T01:29:38.408179Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n#from src.models.T2_model import T2Model\n\nnum_filters = 64\nnum_layers = 1\nd_model = 64\nnum_heads = 16\ndff = 128\nrate = 0.1\n\nmodel = T2Model(num_filters=num_filters, num_classes=num_classes, num_layers=num_layers,\n                d_model=d_model, num_heads=num_heads, dff=dff, input_shape=(sequence_length, feature_dim), rate=rate)\n\nmodel.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.build(input_shape=(sequence_length, feature_dim))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:29:38.409986Z","iopub.execute_input":"2024-04-23T01:29:38.410247Z","iopub.status.idle":"2024-04-23T01:29:39.450952Z","shell.execute_reply.started":"2024-04-23T01:29:38.410225Z","shell.execute_reply":"2024-04-23T01:29:39.450047Z"},"trusted":true},"execution_count":51,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"t2_model\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"t2_model\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ masking_layer (\u001b[38;5;33mMaskingLayer\u001b[0m)    │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m4\u001b[0m),      │             \u001b[38;5;34m0\u001b[0m │\n│                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1000\u001b[0m)]    │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv_embedding (\u001b[38;5;33mConvEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m320\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ positional_encoding             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mPositionalEncoding\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m33,472\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ masking_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaskingLayer</span>)    │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>),      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)]    │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvEmbedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ positional_encoding             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncoding</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,472</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,987\u001b[0m (132.76 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,987</span> (132.76 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,987\u001b[0m (132.76 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,987</span> (132.76 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Callbacks","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfilepath = \"data/best_model.keras\"\n\ncallbacks_list = [\n    EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30),\n    ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, mode='min', verbose=1),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, mode='min', verbose=1),\n]","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:29:39.453027Z","iopub.execute_input":"2024-04-23T01:29:39.453406Z","iopub.status.idle":"2024-04-23T01:29:39.459478Z","shell.execute_reply.started":"2024-04-23T01:29:39.453373Z","shell.execute_reply":"2024-04-23T01:29:39.458432Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    X_train, y_train,\n    epochs=150,\n    batch_size=64,\n    validation_split=0.2,\n    shuffle=True,\n    callbacks=callbacks_list,\n    class_weight=class_weight_dict)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:29:47.058934Z","iopub.execute_input":"2024-04-23T01:29:47.059527Z","iopub.status.idle":"2024-04-23T01:40:09.711174Z","shell.execute_reply.started":"2024-04-23T01:29:47.059496Z","shell.execute_reply":"2024-04-23T01:40:09.709491Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Epoch 1/150\n\u001b[1m   1/1202\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:18:55\u001b[0m 16s/step - accuracy: 0.4062 - loss: 1.1130","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1713835805.629098      89 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1202/1202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.6108 - loss: 0.7822\nEpoch 1: val_loss improved from inf to 0.69205, saving model to data/best_model.keras\n\u001b[1m1202/1202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 207ms/step - accuracy: 0.6108 - loss: 0.7822 - val_accuracy: 0.6387 - val_loss: 0.6921 - learning_rate: 0.0010\nEpoch 2/150\n\u001b[1m1202/1202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7013 - loss: 0.6312\nEpoch 2: val_loss improved from 0.69205 to 0.50813, saving model to data/best_model.keras\n\u001b[1m1202/1202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 195ms/step - accuracy: 0.7014 - loss: 0.6311 - val_accuracy: 0.7821 - val_loss: 0.5081 - learning_rate: 0.0010\nEpoch 3/150\n\u001b[1m 683/1202\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 176ms/step - accuracy: 0.7915 - loss: 0.4781","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/885139417.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                     callbacks.on_train_batch_end(\n\u001b[0m\u001b[1;32m    331\u001b[0m                         \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     )\n\u001b[1;32m    333\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks/progbar_logger.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks/progbar_logger.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_init_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# One-indexed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/progbar.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0minfo\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\" - {k}:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                     avg = backend.convert_to_numpy(\n\u001b[1;32m    163\u001b[0m                         backend.numpy.mean(\n\u001b[0;32m--> 164\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m                         )\n\u001b[1;32m    166\u001b[0m                     )\n\u001b[1;32m    167\u001b[0m                     \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;31m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;31m# object that can implement the operator with knowledge of itself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# and the tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0mRaises\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_truediv_python3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mbound_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1595\u001b[0m           f\"of {{{', '.join([repr(x) for x in _TRUEDIV_TABLE.keys()])}}}.\")\n\u001b[1;32m   1596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mbound_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   8090\u001b[0m         _ctx, \"RealDiv\", name, x, y)\n\u001b[1;32m   8091\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8092\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8093\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8094\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8095\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8096\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8097\u001b[0m       _result = _dispatcher_for_real_div(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"def plot_history(history):\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Val'], loc='upper left')\n    plt.show()\n\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Val'], loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:42:48.716997Z","iopub.execute_input":"2024-04-22T22:42:48.717886Z","iopub.status.idle":"2024-04-22T22:42:48.724654Z","shell.execute_reply.started":"2024-04-22T22:42:48.717847Z","shell.execute_reply":"2024-04-22T22:42:48.723629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:42:49.939238Z","iopub.execute_input":"2024-04-22T22:42:49.939840Z","iopub.status.idle":"2024-04-22T22:42:50.524929Z","shell.execute_reply.started":"2024-04-22T22:42:49.939808Z","shell.execute_reply":"2024-04-22T22:42:50.523970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation on Test data","metadata":{}},{"cell_type":"code","source":"model.load_weights('/kaggle/working/data/best_model.keras')","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:43:11.053334Z","iopub.execute_input":"2024-04-22T22:43:11.054001Z","iopub.status.idle":"2024-04-22T22:43:11.146176Z","shell.execute_reply.started":"2024-04-22T22:43:11.053968Z","shell.execute_reply":"2024-04-22T22:43:11.145306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\nprint(f'Test Loss: {loss:.3f}, Test Accuracy: {accuracy:.3f}')","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:43:14.029336Z","iopub.execute_input":"2024-04-22T22:43:14.030072Z","iopub.status.idle":"2024-04-22T22:43:16.219636Z","shell.execute_reply.started":"2024-04-22T22:43:14.030041Z","shell.execute_reply":"2024-04-22T22:43:16.218675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ny_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = np.argmax(y_test, axis=1)\n\nprint(classification_report(y_true, y_pred_classes, target_names=label_names))","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:43:20.109066Z","iopub.execute_input":"2024-04-22T22:43:20.109764Z","iopub.status.idle":"2024-04-22T22:43:22.690329Z","shell.execute_reply.started":"2024-04-22T22:43:20.109732Z","shell.execute_reply":"2024-04-22T22:43:22.689339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_multi_class_roc(y_test, y_pred, label_names)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(y_true, y_pred_classes, label_names)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_class_accuracy(y_true, y_pred_classes, label_names)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_classification_tradeoff(model, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def predict_and_average(model, X, y_df, label_names):\n    original_ids = np.unique([obj_id.split('_')[0] for obj_id in y_df['obj_id']])\n    predictions_list = []  # Utiliser une liste pour stocker les DataFrames temporaires\n\n    for original_id in original_ids:\n        obj_ids_mask = y_df['obj_id'].str.startswith(original_id)\n        X_obj = X[obj_ids_mask]\n        y_pred_prob = model.predict(X_obj)\n        mean_probs = np.mean(y_pred_prob, axis=0)\n\n        # Préparer la ligne de prédiction\n        pred_row = {'obj_id': original_id}\n        for idx, label in enumerate(label_names):\n            pred_row[f'prob_{label}'] = mean_probs[idx]\n\n        # Ajouter la ligne de prédiction à la liste\n        predictions_list.append(pd.DataFrame([pred_row]))\n\n    # Concaténer toutes les lignes de prédiction en un seul DataFrame\n    predictions = pd.concat(predictions_list, ignore_index=True)\n\n    return predictions\n\n# Exemple d'utilisation\n# Assurez-vous que model, X_test, y_test_df et label_names sont correctement définis\npredictions_df = predict_and_average(model, X_test, y_test_df, label_names)\nprint(predictions_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:18:03.114316Z","iopub.execute_input":"2024-04-22T23:18:03.115084Z","iopub.status.idle":"2024-04-22T23:18:06.339702Z","shell.execute_reply.started":"2024-04-22T23:18:03.115051Z","shell.execute_reply":"2024-04-22T23:18:06.338079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_and_average(model, X, y_df, label_names):\n    original_ids = np.unique([obj_id.split('_')[0] for obj_id in y_df['obj_id']])\n    predictions_list = []  # Utiliser une liste pour stocker les DataFrames temporaires\n\n    for original_id in original_ids:\n        for suffix in ['', '_20', '_50', '_80']:\n            # Identifier les obj_ids spécifiques pour chaque suffixe\n            specific_obj_ids = y_df['obj_id'].str.startswith(original_id + suffix)\n            if not specific_obj_ids.any():\n                continue\n\n            X_obj = X[specific_obj_ids]\n            y_pred_prob = model.predict(X_obj)\n            mean_probs = np.mean(y_pred_prob, axis=0)\n\n            # Obtenir l'étiquette de vérité terrain du premier élément (supposé identique pour tous les éléments avec le même obj_id)\n            ground_truth = y_df[specific_obj_ids]['type'].values[0]\n\n            # Préparer la ligne de prédiction avec le suffixe dans obj_id si nécessaire\n            pred_obj_id = original_id if suffix == '' else original_id + suffix\n            pred_row = {'obj_id': pred_obj_id, 'ground_truth': ground_truth}\n            for idx, label in enumerate(label_names):\n                pred_row[f'prob_{label}'] = mean_probs[idx]\n\n            # Ajouter la ligne de prédiction à la liste\n            predictions_list.append(pd.DataFrame([pred_row]))\n\n    # Concaténer toutes les lignes de prédiction en un seul DataFrame\n    predictions = pd.concat(predictions_list, ignore_index=True)\n\n    return predictions\n\npredictions_df = predict_and_annotate(model, X_test, y_test_df, label_names)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:16:27.110025Z","iopub.execute_input":"2024-04-22T23:16:27.110368Z","iopub.status.idle":"2024-04-22T23:16:27.339536Z","shell.execute_reply.started":"2024-04-22T23:16:27.110344Z","shell.execute_reply":"2024-04-22T23:16:27.338150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_global_performance(predictions_df):\n    # Calculer la moyenne des probabilités pour chaque classe\n    mean_probs = predictions_df.mean(axis=0, numeric_only=True)\n    print(\"Performance Globale Moyenne par Classe:\")\n    print(mean_probs)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:00:55.579760Z","iopub.execute_input":"2024-04-22T23:00:55.580739Z","iopub.status.idle":"2024-04-22T23:00:55.585743Z","shell.execute_reply.started":"2024-04-22T23:00:55.580701Z","shell.execute_reply":"2024-04-22T23:00:55.584678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_global_performance(predictions_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:01:07.180660Z","iopub.execute_input":"2024-04-22T23:01:07.181050Z","iopub.status.idle":"2024-04-22T23:01:07.187946Z","shell.execute_reply.started":"2024-04-22T23:01:07.181019Z","shell.execute_reply":"2024-04-22T23:01:07.186864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_augmentation_performance(predictions_df):\n    # Extraire les types de chaque objet ID (original, _20, _50, _80)\n    augment_types = ['_20', '_50', '_80', 'original']\n    results = {}\n\n    for aug_type in augment_types:\n        if aug_type == 'original':\n            mask = predictions_df['obj_id'].apply(lambda x: '_' not in x)\n        else:\n            mask = predictions_df['obj_id'].str.startswith(aug_type)\n\n        # Calculer la moyenne des probabilités pour le type courant\n        filtered_df = predictions_df[mask]\n        mean_probs = filtered_df.mean(axis=0, numeric_only=True)\n        results[aug_type] = mean_probs\n        print(f\"Performance Moyenne pour {aug_type}:\")\n        print(mean_probs)\n\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:01:53.419385Z","iopub.execute_input":"2024-04-22T23:01:53.419764Z","iopub.status.idle":"2024-04-22T23:01:53.427051Z","shell.execute_reply.started":"2024-04-22T23:01:53.419733Z","shell.execute_reply":"2024-04-22T23:01:53.425869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:02:15.431342Z","iopub.execute_input":"2024-04-22T23:02:15.431709Z","iopub.status.idle":"2024-04-22T23:02:15.444801Z","shell.execute_reply.started":"2024-04-22T23:02:15.431679Z","shell.execute_reply":"2024-04-22T23:02:15.443743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_df","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:23:38.558316Z","iopub.execute_input":"2024-04-22T23:23:38.558732Z","iopub.status.idle":"2024-04-22T23:23:38.570261Z","shell.execute_reply.started":"2024-04-22T23:23:38.558700Z","shell.execute_reply":"2024-04-22T23:23:38.569421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_augmentation_performance(predictions_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:01:54.177581Z","iopub.execute_input":"2024-04-22T23:01:54.177957Z","iopub.status.idle":"2024-04-22T23:01:54.198264Z","shell.execute_reply.started":"2024-04-22T23:01:54.177927Z","shell.execute_reply":"2024-04-22T23:01:54.197324Z"},"trusted":true},"execution_count":null,"outputs":[]}]}